# ── Hardware ─────────────────────────────────────────────────────────
DEVICE=auto                        # auto | cuda | cpu | mps
NUM_WORKERS=4
PIN_MEMORY=true
MIXED_PRECISION=true               # bf16 | fp16 | true (auto) | false

# ── Experiment ───────────────────────────────────────────────────────
EXPERIMENT_NAME=my_experiment
RUN_NAME=run_001
OUTPUT_DIR=./outputs
RESUME_FROM_CHECKPOINT=            # path to checkpoint or leave empty

# ── Training loop ────────────────────────────────────────────────────
EPOCHS=50
BATCH_SIZE=32
EVAL_EVERY_N_EPOCHS=1
SAVE_EVERY_N_EPOCHS=5
EARLY_STOPPING_PATIENCE=10

# ── Optimizer ────────────────────────────────────────────────────────
OPTIMIZER=adamw                    # adam | adamw | sgd | lion | rmsprop
LEARNING_RATE=1e-3
WEIGHT_DECAY=1e-4
MOMENTUM=0.9                       # SGD only
BETAS=0.9,0.999                    # Adam/AdamW

# ── Gradient ─────────────────────────────────────────────────────────
GRADIENT_CLIPPING=1.0              # 0 to disable
GRADIENT_ACCUMULATION_STEPS=1
GRADIENT_CHECKPOINTING=false

# ── Scheduler ────────────────────────────────────────────────────────
SCHEDULER=cosine_warmup            # cosine | cosine_warmup | step | plateau | onecycle | none
WARMUP_STEPS=100
WARMUP_RATIO=0.05                  # overrides WARMUP_STEPS if set
LR_STEP_SIZE=10
LR_GAMMA=0.1
LR_MIN=1e-6

# ── Regularization ───────────────────────────────────────────────────
DROPOUT=0.1
LABEL_SMOOTHING=0.0
STOCHASTIC_DEPTH_RATE=0.0

# ── Reproducibility ──────────────────────────────────────────────────
SEED=42
DETERMINISTIC=false                # true slows training

# ── Tracking ─────────────────────────────────────────────────────────
WANDB_API_KEY=your_wandb_key
WANDB_PROJECT=my-training-project
MLFLOW_TRACKING_URI=http://localhost:5000
LOG_EVERY_N_STEPS=50
