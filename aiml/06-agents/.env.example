# 06-agents — Agent boilerplate config
# All values are overridden by environment variables at runtime.

# ── LLM Providers ─────────────────────────────────────────────────
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-70b-versatile

GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash

CEREBRAS_API_KEY=
CEREBRAS_MODEL=llama3.1-70b

OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=          # leave blank for official OpenAI

OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

LLM_PROVIDER=groq         # active provider: groq|gemini|cerebras|openai|ollama

# ── Agent Settings ─────────────────────────────────────────────────
AGENT_MAX_ITERATIONS=10
AGENT_VERBOSE=true
AGENT_STREAM=false

# ── Tools ──────────────────────────────────────────────────────────
SERPAPI_API_KEY=          # for web search
TAVILY_API_KEY=           # alternative web search
CODE_EXECUTION_TIMEOUT=10 # seconds
TOOL_CALL_RETRIES=2

# ── Memory ─────────────────────────────────────────────────────────
MEMORY_TYPE=buffer        # buffer|summary|vector
MEMORY_MAX_TOKENS=4096
MEMORY_EMBEDDING_MODEL=all-MiniLM-L6-v2
MEMORY_VECTOR_STORE_DIR=./agent_memory

# ── Multi-Agent / Orchestration ─────────────────────────────────────
SUPERVISOR_MODEL=         # overrides LLM_PROVIDER for supervisor node
MAX_WORKERS=4             # parallel worker agents
HANDOFF_TIMEOUT=30        # seconds before a handoff times out

# ── LangGraph ──────────────────────────────────────────────────────
LANGSMITH_API_KEY=        # optional tracing
LANGSMITH_PROJECT=agents-boilerplate
